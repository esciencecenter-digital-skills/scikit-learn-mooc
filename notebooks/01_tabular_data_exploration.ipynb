{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First look at our dataset\n",
    "\n",
    "Assuming you are familiar with pandas dataframes, in this notebook we look at the \n",
    "necessary steps required before any machine learning takes place. It involves:\n",
    "\n",
    "* highlighting that it is crucial to inspect the data before building a model\n",
    "* looking at the variables in the dataset, in particular, differentiate\n",
    "  between numerical and categorical variables, which need different\n",
    "  preprocessing in most machine learning workflows;\n",
    "* visualizing the distribution of the variables to gain some insights into the\n",
    "  dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p><strong>To the instructor</strong></p>\n",
    "<p class=\"last\">Instead of live-coding this notebook, explain the important concepts before ML and show the descriptive statistics.\n",
    "TBC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the adult census dataset\n",
    "\n",
    "We use pandas to load the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "adult_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rows and columns**\n",
    "\n",
    "* Each row in the dataframe represents a \"sample\". In the field of machine learning or\n",
    "descriptive statistics, commonly used equivalent terms are \"record\",\n",
    "\"instance\", or \"observation\". \n",
    "* Each column represents a type of information that has been collected and is\n",
    "called a \"feature\". In the field of machine learning and descriptive\n",
    "statistics, commonly used equivalent terms are \"variable\", \"attribute\", or\n",
    "\"covariate\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "target_column = \"class\"\n",
    "adult_census[target_column].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "**Target and input variables**\n",
    "\n",
    "* Our target variable is the column **class**. \n",
    "* It has two classes: `<=50K` (low-revenue) and\n",
    "`>50K` (high-revenue). \n",
    "* Thus, the prediction problem is a binary classification problem. \n",
    "* The columns other than class are input variables for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "**Categorical and numerical columns**\n",
    "\n",
    "* There are numerical and categorical columns in the data \n",
    "* Numerical columns take continuous values. Example: `\"age\"`\n",
    "* Categorical columns take a finite number of values. Example: \"`native-country`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    \"age\",\n",
    "    \"education-num\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "]\n",
    "categorical_columns = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "]\n",
    "all_columns = numerical_columns + categorical_columns + [target_column]\n",
    "\n",
    "adult_census = adult_census[all_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of samples and the number of columns available in the\n",
    "dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The dataset contains {adult_census.shape[0]} samples and \"\n",
    "    f\"{adult_census.shape[1]} columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the number of features by counting the number of columns and\n",
    "subtract 1, since one of the columns is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset contains {adult_census.shape[1] - 1} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Inspecting the data: individual columns\n",
    "\n",
    "Before building a predictive model, it is a good idea to look at the data:\n",
    "\n",
    "* maybe the task you are trying to achieve can be solved without machine\n",
    "  learning;\n",
    "* you need to check that the information you need for your task is actually\n",
    "  present in the dataset;\n",
    "* inspecting the data is a good way to find peculiarities. These can arise\n",
    "  during data collection (for example, malfunctioning sensor or missing\n",
    "  values), or from the way the data is processed afterwards (for example\n",
    "  capped values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Visually inspecting numerical columns\n",
    "\n",
    "Let's look at the distribution of individual features, to get some insights\n",
    "about the data. We can start by plotting histograms, note that this only works\n",
    "for features containing numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = adult_census.hist(figsize=(20, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can already make a few comments about some of the variables:\n",
    "\n",
    "* `\"age\"`: there are not that many points for `age > 70`. The dataset\n",
    "  description does indicate that retired people have been filtered out\n",
    "  (`hours-per-week > 0`);\n",
    "* `\"education-num\"`: peak at 10 and 13. These are the number of years of education.\n",
    "* `\"hours-per-week\"` peaks at 40, this was very likely the standard number of\n",
    "  working hours at the time of the data collection;\n",
    "* most values of `\"capital-gain\"` and `\"capital-loss\"` are close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting categorical columns \n",
    "\n",
    "For categorical variables, we can look at the distribution of values:\n",
    "* We should do this for both the target variable and the input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "adult_census[target_column].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### Class imbalance\n",
    "**Imbalance in the target variable**\n",
    "\n",
    "* Classes are slightly imbalanced, meaning there are more samples of one\n",
    "or more classes compared to others. \n",
    "* In this case, we have many more samples with `\" <=50K\"` than with `\" >50K\"`. \n",
    "* Class imbalance in the target variable happens often in practice\n",
    "and may need special techniques when building a predictive model.\n",
    "* For example in a medical setting, if we are trying to predict whether subjects\n",
    "may develop a rare disease, there would be a lot more healthy subjects than\n",
    "ill subjects in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Imbalance in the input data** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "* The data collection process led to an important imbalance \n",
    "between the number of male/female samples. Thus, our data are **not representative** of the US population.\n",
    "* Training a model with such data imbalance can cause\n",
    "disproportioned prediction errors for the under-represented groups. \n",
    "* This is a typical cause of\n",
    "[fairness](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml#what-is-machine-learning-fairness)\n",
    "problems if used naively when deploying a machine learning based system in a\n",
    "real life setting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404e435",
   "metadata": {},
   "source": [
    "## Inspecting relationships between columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In pandas\n",
    "\n",
    "* We can use the crosstabulation feature from pandas to see how two variables are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    index=adult_census[\"education\"], columns=adult_census[\"education-num\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Redundante columns**\n",
    "* For every entry in `\"education\"`, there is only one single corresponding\n",
    "value in `\"education-num\"`. \n",
    "* This shows that `\"education\"` and `\"education-num\"` give you the same information. \n",
    "* Thus, we can remove `\"education-num\"` without losing information. \n",
    "* Note that having redundant (or highly correlated) columns can be a problem for machine\n",
    "learning algorithms.\n",
    "\n",
    "We drop this column now and in all future notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census = adult_census.drop(columns=[\"education\"]) # duplicated in categorical column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pairplots\n",
    "\n",
    "Another way to inspect the relationship between variables is to do a `pairplot` and show how each\n",
    "variable differs according to our target, i.e. `\"class\"`. Plots along the\n",
    "diagonal show the distribution of individual variables for each `\"class\"`. The\n",
    "plots on the off-diagonal can reveal interesting interactions between\n",
    "variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# We plot a subset of the data to keep the plot readable and make the plotting\n",
    "# faster\n",
    "n_samples_to_plot = 5000\n",
    "columns = [\"age\", \"education-num\", \"hours-per-week\"]\n",
    "_ = sns.pairplot(\n",
    "    data=adult_census[:n_samples_to_plot],\n",
    "    vars=columns,\n",
    "    hue=target_column,\n",
    "    plot_kws={\"alpha\": 0.2},\n",
    "    height=3,\n",
    "    diag_kind=\"hist\",\n",
    "    diag_kws={\"bins\": 30},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards making predictions: creating decision rules by hand\n",
    "\n",
    "By looking at the previous plots, we could create some hand-written rules that\n",
    "predict whether someone has a high- or low-income. For instance, we could\n",
    "focus on the combination of the `\"hours-per-week\"` and `\"age\"` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(\n",
    "    x=\"age\",\n",
    "    y=\"hours-per-week\",\n",
    "    data=adult_census[:n_samples_to_plot],\n",
    "    hue=target_column,\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* The data points (circles) show the distribution of `\"hours-per-week\"` and\n",
    "`\"age\"` in the dataset. \n",
    "* Blue points mean low-income and orange points mean high-income. \n",
    "* This part of the plot is the same as the bottom-left plot in the pairplot above.\n",
    "\n",
    "In this plot, we can try to find regions that mainly contains a single class\n",
    "such that we can easily decide what class one should predict. We could come up\n",
    "with hand-written rules as shown in this plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.scatterplot(\n",
    "    x=\"age\",\n",
    "    y=\"hours-per-week\",\n",
    "    data=adult_census[:n_samples_to_plot],\n",
    "    hue=target_column,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "age_limit = 27\n",
    "plt.axvline(x=age_limit, ymin=0, ymax=1, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "hours_per_week_limit = 40\n",
    "plt.axhline(\n",
    "    y=hours_per_week_limit, xmin=0.18, xmax=1, color=\"black\", linestyle=\"--\"\n",
    ")\n",
    "\n",
    "plt.annotate(\"<=50K\", (17, 25), rotation=90, fontsize=35)\n",
    "plt.annotate(\"<=50K\", (35, 20), fontsize=35)\n",
    "_ = plt.annotate(\"???\", (45, 60), fontsize=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "* In the region `age < 27` (left region) the prediction is low-income. Indeed,\n",
    "  there are many blue points and we cannot see any orange points.\n",
    "* In the region `age > 27 AND hours-per-week < 40` (bottom-right region), the\n",
    "  prediction is low-income. Indeed, there are many blue points and only a few\n",
    "  orange points.\n",
    "* In the region `age > 27 AND hours-per-week > 40` (top-right region), we see\n",
    "  a mix of blue points and orange points. It seems complicated to choose which\n",
    "  class we should predict in this region.\n",
    "\n",
    "**Some machine learning models work similarly to what we just did**\n",
    "\n",
    "* We choose the two thresholds (27 years and 40 hours) arbitrarily\n",
    "* Decision trees work similarly, but more systematically and in a more scalable way\n",
    "  * Decision trees are systematic: They choose the \"best\" splits based on data without human intervention or inspection.\n",
    "  * Decision trees scale: They easily handle data with many more columns, which is difficult for humans.\n",
    "* We cover decision trees later in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Notebook Recap\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "* looked at the different kind of variables to differentiate between\n",
    "  categorical and numerical variables;\n",
    "* inspected the data with `pandas` and `seaborn`. Data inspection can allow\n",
    "  you to decide whether using machine learning is appropriate for your data\n",
    "  and to highlight potential peculiarities in your data.\n",
    "\n",
    "We made important observations (which will be discussed later in more detail):\n",
    "\n",
    "* if your target variable is imbalanced (e.g., you have more samples from one\n",
    "  target category than another), you may need special techniques for training\n",
    "  and evaluating your machine learning model;\n",
    "* having redundant (or highly correlated) columns can be a problem for some\n",
    "  machine learning algorithms;\n",
    "* contrary to decision tree, linear models can only capture linear\n",
    "  interactions, so be aware of non-linear relationships in your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "**Data**\n",
    "\n",
    "We use data from the 1994 US census that we downloaded from\n",
    "[OpenML](http://openml.org/).\n",
    "\n",
    "You can look at the OpenML webpage to learn more about this dataset:\n",
    "<http://www.openml.org/d/1590>\n",
    "\n",
    "**Fairness in ML**\n",
    "\n",
    "We recommend our readers to refer to [fairlearn.org](https://fairlearn.org)\n",
    "for resources on how to quantify and potentially mitigate fairness issues\n",
    "related to the deployment of automated decision making systems that rely on\n",
    "machine learning components.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
